First and foremost, we had to decide whether we wanted to use still images, live recorded segments, or a combination for both. To properly represent the functionality of our app, we had to be able to show the user in different locations (airport, different countries) that were not accessible to us, and also display our prototype interface screens onto the mobile and smartwatch device. Such tasks are too difficult for us to edit with live recorded segments, so we opted to use just still images since it was much easier to photoshop a user in different locations and photoshop our prototype interface screens onto the actual devices. Thus, after creating a storyboard for our video, identifying the tasks we wanted to portray, and drawing a list of all the different pictures that we needed to take to represent each scene, we had a member of our team act as the user and took pictures of him performing various activities we needed for our video. The pictures were then photoshopped accordingly to what was needed, and was organized by scene and by order of appearance. From these images, a rough script for the narration was produced as well as a prelimiary video to serve as a baseline to work off of and improve upon. Our designated narrator then went over the script and video, made final changes to the script, and communicated to our deisgnated video editor which images in the video needed to have a longer or shorter duration. Once the video contained the proper timing of all images, our narrator recorded her narration, and our video editor added the narration to the video, creating the final video prototype that was published.

We did not come up with any unique techniques, but something we saw from another video prototype we thought was really neat was how a series of still images were rapidly  displayed in succession to create the impression of actual movement. In fact, some of our members thought that those particular scenes were live recorded segments at first, until they watched it again and realized that the images were instead animated to produce the illusion of movement. Clearly impressed, we also decided to incorporate this element into our video.

The good aspects of our video prototyping technique is that it was relatively easy to accomplish, since all that is required is the use of still images and photoshop to produce the pictures we needed to represent the functionality of our app. This is much more efficient and far less time consuming to using live recorded segments, which are cost a lot of time to capture (due to having to travel to appropriate locations and often doing multiple takes), and even harder to edit if special effects are required (such as projecting the prototype interface onto an actual device in the video). With live recorded segments, the narration must also be adapted to the length of the pre-recorded video segments, or vice-versa, potentially resulting in rushed delivery or empty moments of silence where timings don't match up, but still images allows us to be more flexible in that we can easily adjust the duration of particular images to match the narration to create a more fluent presentation.

The difficult aspects of our prototyping technique was in regards to composing the video. We had one member responsbile for the narration and another member responsible for putting the video together, and our intial plan to produce the video was not efficient. We originally decided for our narrator to create a narration based on the images that we gathered, with the intent that that the video editor could insert her narration and adjust the image durations based on her narration afterwards, but we did not consider how the narrator would convey her intent (such as which part of the narration is for which image) to the video editor. Thus, we had the video editor compose a video with estimated image durations to serve as a guide, and intended for the narrator the guide video to record the narration and tell the video editor to shorten or lengthen the duration of certain images, but it was could not be done over the web as we hoped since aspects regarding the specific timing and duration of images is much easier to discuss in person. Thus in the end, the narrator and video editor met in person to work on the video, which made communication and the production process much faster than how long it would have took if they had tried to work separately.